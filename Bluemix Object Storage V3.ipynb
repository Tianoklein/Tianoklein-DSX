{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "## Existem dois tipos de Storage na Cloud. \n - Object Storage (Swift API )\n - Cloud Object Storage (Beta)\n - ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Object Storage (Swift API )\n -Fonte:https://medium.com/ibm-data-science-experience/working-with-object-storage-in-data-science-experience-python-edition-c96bc6c6101", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Enviado o .CSV / .JSON local para o Object Storage (Swift API )", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "## Fun\u00e7ao PutFile\nfrom io import BytesIO  \nimport requests  \nimport json  \nimport pandas as pd\n\ndef put_file(credentials, local_file_name):  \n    \"\"\"This functions returns a StringIO object containing\n    the file content from Bluemix Object Storage V3.\"\"\"\n    f = open(local_file_name,'r')\n    my_data = f.read()\n    url1 = ''.join(['https://identity.open.softlayer.com', '/v3/auth/tokens'])\n    data = {'auth': {'identity': {'methods': ['password'],\n            'password': {'user': {'name': credentials['username'],'domain': {'id': credentials['domain_id']},\n            'password': credentials['password']}}}}}\n    headers1 = {'Content-Type': 'application/json'}\n    resp1 = requests.post(url=url1, data=json.dumps(data), headers=headers1)\n    resp1_body = resp1.json()\n    for e1 in resp1_body['token']['catalog']:\n        if(e1['type']=='object-store'):\n            for e2 in e1['endpoints']:\n                        if(e2['interface']=='public'and e2['region']=='dallas'):\n                            url2 = ''.join([e2['url'],'/', credentials['container'], '/', local_file_name])\n    s_subject_token = resp1.headers['x-subject-token']\n    headers2 = {'X-Auth-Token': s_subject_token, 'accept': 'application/json'}\n    resp2 = requests.put(url=url2, headers=headers2, data = my_data )\n    print (resp2)"
        }, 
        {
            "source": "#### Credentials antigo!\n <font color='red'> __\"User Imput\"__ <font>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#Chama Fun\u00e7\u00e3o com parametros.\nput_file(credentials_2,'320840714747443_facebook_comments.csv')\n\n\n\n#For example, if you are working with a Pandas data frame (df), you could save it with the following code:\ndf.to_csv('myPandasData.csv',index=False)\n\n#If you are working with JSON/Python dictionaries, you can save those using the following code:\nwith open('my_json.json', 'w') as my_json_file: \n    json.dump(my_json, my_json_file)"
        }, 
        {
            "source": "## Lendo um arquivo", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Update 12/02/2016\u200a\u2014\u200aData Science Experience now \n# supports one-click importing of JSON data inside Python and R notebooks.\n# The code below will still work in DSX and may be helpful for reference.\nfrom io import BytesIO\nimport requests \nimport json \nimport pandas as pd \n\ndef get_data(credentials): \n    \"\"\"This functions returns a StringIO object containing the file    content from Bluemix Object Storage V3.\"\"\" \n    url1 = ''.join(['https://identity.open.softlayer.com', '/v3/auth/tokens']) \n    data = {'auth': {'identity': {'methods': ['password'], 'password': {'user': {'name': credentials['username'],'domain': {'id': credentials['domain_id']}, 'password': credentials['password']}}}}} \n    headers1 = {'Content-Type': 'application/json'} resp1 = requests.post(url=url1, data=json.dumps(data), headers=headers1) \n    resp1_body = resp1.json() \n    for e1 in resp1_body['token']['catalog']:\n        if(e1['type']=='object-store'): \n            for e2 in e1['endpoints']:   \n                if(e2['interface']=='public'and e2['region']=='dallas'): url2 = ''.join([e2['url'],'/', credentials['container'], '/', credentials['filename']]) s_subject_token = resp1.headers['x-subject-token'] headers2 = {'X-Auth-Token': s_subject_token, 'accept': 'application/json'} \nresp2 = requests.get(url=url2, headers=headers2) \nreturn json.loads(resp2.content)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "my_json = get_data(credentials_1) my_json_df = pd.DataFrame.from_dict(my_json)"
        }, 
        {
            "source": "# Cloud Object Storage (Beta)\n -Fonte: https://medium.com/ibm-data-science-experience/working-with-ibm-cloud-object-storage-in-python-fe0ba8667d5f", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "source": "#### *ibm_boto3* library provides complete access to the IBM\u00ae Cloud Object Storage API. We need to create a low-level client using above credentials.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from botocore.client import Config\nimport ibm_boto3\ncos = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id=credentials['IBM_API_KEY_ID'],\n    ibm_service_instance_id=credentials['IAM_SERVICE_ID'],\n    ibm_auth_endpoint=credentials['IBM_AUTH_ENDPOINT'],\n    config=Config(signature_version='oauth'),\n    endpoint_url=credentials['ENDPOINT'])"
        }, 
        {
            "source": "### Upload Files", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "cos.upload_file(Filename='tweets.csv',Bucket=credentials['BUCKET'],Key='tweets.csv')\ncos.upload_file(Filename='195033580530033_facebook_statuses.csv',Bucket=credentials['BUCKET'],Key='195033580530033_facebook_statuses.csv')\ncos.upload_file(Filename='195033580530033_facebook_comments.csv',Bucket=credentials['BUCKET'],Key='195033580530033_facebook_comments.csv')\ncos.upload_file(Filename='320840714747443_facebook_statuses.csv',Bucket=credentials['BUCKET'],Key='320840714747443_facebook_statuses.csv')\ncos.upload_file(Filename='320840714747443_facebook_comments.csv',Bucket=credentials['BUCKET'],Key='320840714747443_facebook_comments.csv')\ncos.upload_file(Filename='188308137863445_facebook_comments.csv',Bucket=credentials['BUCKET'],Key='188308137863445_facebook_comments.csv')\ncos.upload_file(Filename='188308137863445_facebook_statuses.csv',Bucket=credentials['BUCKET'],Key='188308137863445_facebook_statuses.csv')"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "##ACHO QUE \u00c9 SO EXEMPLO: N\u00c3O SEI SE PRECISA RODAR ISSO PARA FUNCIONAR.\nfrom botocore.client import Config\nimport ibm_boto3\ndef upload_file_cos(credentials,local_file_name,key):  \n    cos = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id=credentials['IBM_API_KEY_ID'],\n    ibm_service_instance_id=credentials['IAM_SERVICE_ID'],\n    ibm_auth_endpoint=credentials['IBM_AUTH_ENDPOINT'],\n    config=Config(signature_version='oauth'),\n    endpoint_url=credentials['ENDPOINT'])\n    try:\n        res=cos.upload_file(Filename=local_file_name, Bucket=credentials['BUCKET'],Key=key)\n    except Exception, e:\n        print(Exception, e)\n    else:\n        print('File Uploaded')"
        }, 
        {
            "source": "### Download Files To Local Machine", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "cos.download_file(Bucket=credentials['BUCKET'],Key='tweets.csv',Filename='tweets.csv')"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from botocore.client import Config\nimport ibm_boto3\ndef download_file_cos(credentials,local_file_name,key):  \n    cos = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id=credentials['IBM_API_KEY_ID'],\n    ibm_service_instance_id=credentials['IAM_SERVICE_ID'],\n    ibm_auth_endpoint=credentials['IBM_AUTH_ENDPOINT'],\n    config=Config(signature_version='oauth'),\n    endpoint_url=credentials['ENDPOINT'])\n    try:\n        res=cos.download_file(Bucket=credentials['BUCKET'],Key=key,Filename=local_file_name)\n    except Exception, e:\n        print(Exception, e)\n    else:\n        print('File Downloaded')"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "with open('wine.csv', 'rb') as data:\n    cos.upload_fileobj(data,  credentials['BUCKET'], 'wine_bytes')\n\nwith open('wine_copy.csv', 'wb') as data:\n    cos.download_fileobj(credentials['BUCKET'], 'wine_bytes', data)"
        }, 
        {
            "source": "**Obs**:Credentials you get in DSX using insert credentials options are scoped to one bucket access permission i.e. they allow you to only interact with your project\u2019s bucket. If you want to interact with other buckets then you will have to create new credentials with appropriate access permissions", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.1", 
            "name": "python2-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.11", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython2", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}